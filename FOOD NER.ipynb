{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5bdd420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import spacy \n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "#from wordcloud import WordCloud, STOPWORDS\n",
    "from spacy.util import minibatch, compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a08b9eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data \n",
    "df = pd.read_csv(\"FOOD list1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "df471434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jelly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Honey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Firnee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Halua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Coffee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Food Name\n",
       "0     Jelly\n",
       "1     Honey\n",
       "2    Butter\n",
       "3      Eggs\n",
       "4    Banana\n",
       "5      Cake\n",
       "6    Firnee\n",
       "7     Halua\n",
       "8       Tea\n",
       "9    Coffee"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8e693b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3d54c102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1cb7ef713d0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee9cc9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get All Components of this NLP Object\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "46261766",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e20502c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London GPE\n",
      "Ibuprofen ORG\n",
      "last year 2019 DATE\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "ex1 = \"MR. Jawad eat kacchi biriyani every days\"\n",
    "ex2 = \"James went to London to buy Ibuprofen last year 2019\"\n",
    "\n",
    "doc = nlp(ex2)\n",
    "# Check for entities\n",
    "for entity in doc.ents:\n",
    "  print(entity,entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "661b3b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the data \n",
    "\n",
    "def food_name(name):\n",
    "    processed_token = []\n",
    "    for token in name.split():\n",
    "        token = ''.join(e.lower() for e in token if e.isalnum())\n",
    "        processed_token.append(token)\n",
    "    return ' '.join(processed_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b0133de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Food Names\n",
    "df.head()\n",
    "all_food = df['Food Name'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e721440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_food = [x.lower() for x in all_food]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6846475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "679af5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "TRAIN_DATA = []\n",
    "for _, item in df.iterrows():\n",
    "    ent_dict = {}\n",
    "    if count < 100000:\n",
    "        name = food_name(item['Food Name'])\n",
    "        #Locate foods and their positions\n",
    "        visited_items = []\n",
    "        entities = []\n",
    "        for token in name.split():\n",
    "            if token in all_food:\n",
    "                for i in re.finditer(token, name):\n",
    "                        entity = (i.span()[0], i.span()[1], 'FOOD')\n",
    "                        visited_items.append(token)\n",
    "                        entities.append(entity)\n",
    "        if len(entities) > 0:\n",
    "            ent_dict['entities'] = entities\n",
    "            train_item = (name, ent_dict)\n",
    "            TRAIN_DATA.append(train_item)\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fbcd4e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d7add9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jelly', {'entities': [(0, 5, 'FOOD')]}),\n",
       " ('honey', {'entities': [(0, 5, 'FOOD')]}),\n",
       " ('butter', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('eggs', {'entities': [(0, 4, 'FOOD')]}),\n",
       " ('banana', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('cake', {'entities': [(0, 4, 'FOOD')]}),\n",
       " ('firnee', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('halua', {'entities': [(0, 5, 'FOOD')]}),\n",
       " ('tea', {'entities': [(0, 3, 'FOOD')]}),\n",
       " ('coffee', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('parata', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('chapati', {'entities': [(0, 7, 'FOOD')]}),\n",
       " ('toast', {'entities': [(0, 5, 'FOOD')]}),\n",
       " ('sugar', {'entities': [(0, 5, 'FOOD')]}),\n",
       " ('milk', {'entities': [(0, 4, 'FOOD')]}),\n",
       " ('bhajee', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('banana', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('papaya', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('apple', {'entities': [(0, 5, 'FOOD')]}),\n",
       " ('orange', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('grapes', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('mango', {'entities': [(0, 5, 'FOOD')]}),\n",
       " ('fish', {'entities': [(0, 4, 'FOOD')]}),\n",
       " ('salad', {'entities': [(0, 5, 'FOOD')]}),\n",
       " ('mineral', {'entities': [(0, 7, 'FOOD')]}),\n",
       " ('mishti', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('doi', {'entities': [(0, 3, 'FOOD')]}),\n",
       " ('chira', {'entities': [(0, 5, 'FOOD')]}),\n",
       " ('muri', {'entities': [(0, 4, 'FOOD')]}),\n",
       " ('bharta', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('korolla', {'entities': [(0, 7, 'FOOD')]}),\n",
       " ('potol', {'entities': [(0, 5, 'FOOD')]}),\n",
       " ('lobster', {'entities': [(0, 7, 'FOOD')]}),\n",
       " ('prawn', {'entities': [(0, 5, 'FOOD')]}),\n",
       " ('mango', {'entities': [(0, 5, 'FOOD')]}),\n",
       " ('jackfruite', {'entities': [(0, 10, 'FOOD')]}),\n",
       " ('graps', {'entities': [(0, 5, 'FOOD')]}),\n",
       " ('kensington', {'entities': [(0, 10, 'FOOD')]}),\n",
       " ('burger', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('vharta', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('bhajee', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('shutki', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('muffin', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('goza', {'entities': [(0, 4, 'FOOD')]}),\n",
       " ('sandwitch', {'entities': [(0, 9, 'FOOD')]}),\n",
       " ('hotdog', {'entities': [(0, 6, 'FOOD')]}),\n",
       " ('frenchfry', {'entities': [(0, 9, 'FOOD')]})]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98857517",
   "metadata": {},
   "source": [
    "###### Training the Food NER model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "12d77cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the ner component\n",
    "ner=nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8890b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "def train_ner(training_data):\n",
    "    \"\"\"Steps\n",
    "    Create a Blank NLP  model object\n",
    "    Create and add NER to the NLP model\n",
    "    Add Labels from your training data\n",
    "    Train  \n",
    "    \"\"\"\n",
    "    TRAIN_DATA = training_data\n",
    "    nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "    print(\"Created blank 'en' model\")\n",
    "    \n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner =  nlp.add_pipe(\"ner\")\n",
    "        #nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "        \n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "            \n",
    "    nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            example = []\n",
    "            # Update the model with iterating each text\n",
    "            from spacy.training import Example\n",
    "            for i in range(len(texts)):\n",
    "                doc = nlp.make_doc(texts[i])\n",
    "                example.append(Example.from_dict(doc, annotations[i]))\n",
    "                #update the model\n",
    "            ner.update(\n",
    "                example,  # batch of annotations\n",
    "                drop=0.5,  # dropout - make it harder to memorise data\n",
    "                losses=losses,\n",
    "            )\n",
    "        print(\"Losses\", losses)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2c0acee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Losses {'ner': 39.16666841506958}\n",
      "Losses {'ner': 39.16666841506958}\n",
      "Losses {'ner': 39.16666841506958}\n",
      "Losses {'ner': 39.16666841506958}\n",
      "Losses {'ner': 39.16666841506958}\n",
      "Losses {'ner': 39.16666841506958}\n",
      "Losses {'ner': 39.16666841506958}\n",
      "Losses {'ner': 39.16666841506958}\n",
      "Losses {'ner': 39.16666841506958}\n",
      "Losses {'ner': 39.16666841506958}\n"
     ]
    }
   ],
   "source": [
    "nlp=train_ner(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b407324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "62230377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(graps, 'FOOD')]\n",
      "[(vharta, 'FOOD')]\n",
      "[(sandwitch, 'FOOD')]\n",
      "[(mango, 'FOOD')]\n",
      "[(salad, 'FOOD')]\n",
      "[(bhajee, 'FOOD')]\n",
      "[(korolla, 'FOOD')]\n",
      "[(halua, 'FOOD')]\n",
      "[(banana, 'FOOD')]\n",
      "[(burger, 'FOOD')]\n",
      "[(muri, 'FOOD')]\n",
      "[(mango, 'FOOD')]\n",
      "[(bhajee, 'FOOD')]\n",
      "[(grapes, 'FOOD')]\n",
      "[(parata, 'FOOD')]\n",
      "[(sugar, 'FOOD')]\n",
      "[(shutki, 'FOOD')]\n",
      "[(coffee, 'FOOD')]\n",
      "[(jelly, 'FOOD')]\n",
      "[(orange, 'FOOD')]\n",
      "[(toast, 'FOOD')]\n",
      "[(cake, 'FOOD')]\n",
      "[(honey, 'FOOD')]\n",
      "[(butter, 'FOOD')]\n",
      "[(banana, 'FOOD')]\n",
      "[(potol, 'FOOD')]\n",
      "[(lobster, 'FOOD')]\n",
      "[(eggs, 'FOOD')]\n",
      "[(tea, 'FOOD')]\n",
      "[(papaya, 'FOOD')]\n",
      "[(doi, 'FOOD')]\n",
      "[(firnee, 'FOOD')]\n",
      "[(frenchfry, 'FOOD')]\n",
      "[(bharta, 'FOOD')]\n",
      "[(milk, 'FOOD')]\n",
      "[(fish, 'FOOD')]\n",
      "[(goza, 'FOOD')]\n",
      "[(apple, 'FOOD')]\n",
      "[(chapati, 'FOOD')]\n",
      "[(mishti, 'FOOD')]\n",
      "[(prawn, 'FOOD')]\n",
      "[(mineral, 'FOOD')]\n",
      "[(muffin, 'FOOD')]\n",
      "[(jackfruite, 'FOOD')]\n",
      "[(chira, 'FOOD')]\n",
      "[(kensington, 'FOOD')]\n",
      "[(hotdog, 'FOOD')]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "for text,_ in TRAIN_DATA[:1000]:\n",
    "    doc = nlp1(text)\n",
    "    result = [(ent,ent.label_) for ent in doc.ents]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "45f3a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_food_entity(text):\n",
    "    docx =  nlp1(text)\n",
    "    result = [(ent,ent.label_) for ent in docx.ents]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dfa6336b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(hotdog, 'FOOD')]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "68a0b979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Jelly\n",
       "1     Honey\n",
       "2    Butter\n",
       "3      Eggs\n",
       "4    Banana\n",
       "5      Cake\n",
       "6    Firnee\n",
       "7     Halua\n",
       "8       Tea\n",
       "9    Coffee\n",
       "Name: Food Name, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Food Name'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3a848f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [((Jelly), FOOD)]\n",
       "1     [((Honey), FOOD)]\n",
       "2    [((Butter), FOOD)]\n",
       "3      [((Eggs), FOOD)]\n",
       "4    [((Banana), FOOD)]\n",
       "5      [((Cake), FOOD)]\n",
       "6    [((Firnee), FOOD)]\n",
       "7     [((Halua), FOOD)]\n",
       "8       [((Tea), FOOD)]\n",
       "9    [((Coffee), FOOD)]\n",
       "Name: Food Name, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Food Name'][0:10].apply(extract_food_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "85191243",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex3 = \"Rahim's favourite fish bhoona cooked by his sister . His mother cooked Firnee for him\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bf79f42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rahim FOOD\n",
      "'s FOOD\n",
      "favourite FOOD\n",
      "fish FOOD\n",
      "bhoona FOOD\n",
      "cooked FOOD\n",
      "by FOOD\n",
      "his FOOD\n",
      "sister FOOD\n",
      ". FOOD\n",
      "His FOOD\n",
      "mother FOOD\n",
      "cooked FOOD\n",
      "Firnee FOOD\n",
      "for FOOD\n",
      "him FOOD\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp1(ex3)\n",
    "for entity in doc1.ents:\n",
    "    print(entity,entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1062d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ad1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659abdd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
